from vertexai.preview.language_models import ChatModel, InputOutputTextPair, TextGenerationModel
import re
from itertools import cycle, islice
from random import randint

### functions in this file use AI models to process the messages

# helper functions

def take(n, iterable):
    "Return first n items of the iterable as a list"
    return list(islice(iterable, n))


# AI functions

def chat(msg: str):
    chat_model = ChatModel.from_pretrained("chat-bison@001")
    parameters = {
        "temperature": 0.8,
        "max_output_tokens": 1024,
        "top_p": 0.8,
        "top_k": 40,
    }
    chat = chat_model.start_chat(  # Initialize the chat with model
        # chat context and examples go here
    )
    # Send the human message to the model and get a response
    response = chat.send_message(msg, **parameters)
    # Return the model's response
    return response.text


def summary(msg: str):
    msg = """Please write everything in an active voice, i.e. instead of writing "the author", write "I"! Use enthusiastic and interesting language!
    
Provide a summary with about three sentences for the following article: Beyond our own products, we think it\'s important to make it easy, safe and scalable for others to benefit from these advances by building on top of our best models. Next month, we\'ll start onboarding individual developers, creators and enterprises so they can try our Generative Language API, initially powered by LaMDA with a range of models to follow. Over time, we intend to create a suite of tools and APIs that will make it easy for others to build more innovative applications with AI. Having the necessary compute power to build reliable and trustworthy AI systems is also crucial to startups, and we are excited to help scale these efforts through our Google Cloud partnerships with Cohere, C3.ai and Anthropic, which was just announced last week. Stay tuned for more developer details soon.
Summary: Google is making its AI technology more accessible to developers, creators, and enterprises. Next month, Google will start onboarding developers to try its Generative Language API, which will initially be powered by LaMDA. Over time, Google intends to create a suite of tools and APIs that will make it easy for others to build more innovative applications with AI. Google is also excited to help scale these efforts through its Google Cloud partnerships with Cohere, C3.ai, and Anthropic.

Provide a summary with about three sentences for the following article: The benefits of electricPromptData kitchens go beyond climate impact, starting with speed. The first time I ever cooked on induction (electric) equipment, the biggest surprise was just how incredibly fast it is. In fact, induction boils water twice as fast as traditional gas equipment and is far more efficient â€” because unlike a flame, electric heat has nowhere to escape. At Bay View, our training programs help Google chefs appreciate and adjust to the new pace of induction. The speed truly opens up whole new ways of cooking.
Summary: Electric kitchens are faster, more efficient, and better for the environment than gas kitchens. Induction cooking is particularly fast, boiling water twice as fast as traditional gas equipment. This speed opens up whole new ways of cooking. Google chefs are trained to appreciate and adjust to the new pace of induction cooking at Bay View.

Provide a summary with about three sentences for the following article: We\'re also using AI to forecast floods, another extreme weather pattern exacerbated by climate change. We\'ve already helped communities to predict when floods will hit and how deep the waters will get â€” in 2021, we sent 115 million flood alert notifications to 23 million people over Google Search and Maps, helping save countless lives. Today, we\'re sharing that we\'re now expanding our coverage to more countries in South America (Brazil and Colombia), Sub-Saharan Africa (Burkina Faso, Cameroon, Chad, Democratic Republic of Congo, Ivory Coast, Ghana, Guinea, Malawi, Nigeria, Sierra Leone, Angola, South Sudan, Namibia, Liberia, and South Africa), and South Asia (Sri Lanka). We\'ve used an AI technique called transfer learning to make it work in areas where there\'s less data available. We\'re also announcing the global launch of Google FloodHub, a new platform that displays when and where floods may occur. We\'ll also be bringing this information to Google Search and Maps in the future to help more people to reach safety in flooding situations.
Summary: Google is using AI to forecast floods in South America, Sub-Saharan Africa, South Asia, and other parts of the world. The AI technique of transfer learning is being used to make it work in areas where there\'s less data available. Google FloodHub, a new platform that displays when and where floods may occur, has also been launched globally. This information will also be brought to Google Search and Maps in the future to help more people reach safety in flooding situations.

Provide a summary with about three sentences for the following article: In order to learn skiing, you must first be educated on the proper use of the equipment. This includes learning how to properly fit your boot on your foot, understand the different functions of the ski, and bring gloves, goggles etc. Your instructor starts you with one-footed ski drills. Stepping side-to-side, forward-and-backward, making snow angels while keeping your ski flat to the ground, and gliding with the foot not attached to a ski up for several seconds. Then you can put on both skis and get used to doing them with two skis on at once. Next, before going down the hill, you must first learn how to walk on the flat ground and up small hills through two methods, known as side stepping and herringbone. Now it\'s time to get skiing! For your first attempted run, you will use the skills you just learned on walking up the hill, to go down a small five foot vertical straight run, in which you will naturally stop on the flat ground. This makes you learn the proper athletic stance to balance and get you used to going down the hill in a safe, controlled setting. What do you need next? To be able to stop yourself. Here, your coach will teach you how to turn your skis into a wedge, also commonly referred to as a pizza, by rotating legs inward and pushing out on the heels. Once learned, you practice a gliding wedge down a small hill where you gradually come to a stop on the flat ground thanks to your wedge. Finally, you learn the necessary skill of getting up after falling, which is much easier than it looks, but once learned, a piece of cake.
Summary: Skiing is a great way to enjoy the outdoors and get some exercise. It can be a little daunting at first, but with a little practice, you\'ll be skiing like a pro in no time.

Provide a summary with about three sentences for the following article: Yellowstone National Park is an American national park located in the western United States, largely in the northwest corner of Wyoming and extending into Montana and Idaho. It was established by the 42nd U.S. Congress with the Yellowstone National Park Protection Act and signed into law by President Ulysses S. Grant on March 1, 1872. Yellowstone was the first national park in the U.S. and is also widely held to be the first national park in the world.The park is known for its wildlife and its many geothermal features, especially the Old Faithful geyser, one of its most popular. While it represents many types of biomes, the subalpine forest is the most abundant. It is part of the South Central Rockies forests ecoregion.
Summary: Yellowstone National Park is the first national park in the United States and the world. It is located in the western United States, largely in the northwest corner of Wyoming and extending into Montana and Idaho. The park is known for its wildlife and its many geothermal features, especially the Old Faithful geyser.

Provide a summary with about three sentences for the following article: """ + msg + """
Summary:"""

    model = TextGenerationModel.from_pretrained("text-bison@001")
    parameters = {
        "temperature": 0.2,
        "max_output_tokens": 500,
        "top_p": 0.95,
        "top_k": 40
    }
    response = model.predict(msg, **parameters)
    return response.text


def hashtags(msg: str):
    
    def sanitize_hashtags(s: str):
        """
        Hashtags should only include hashtags, separated by spaces, and without duplicates.
        A hashtag is a # sign followed by letters, numbers and underscores - all other characters should be removed.

        For example:
        "#obsidian, #markdown, #notion, #org-mode, #data view, #tag folder, #openstreetmap, #acl, #markdown, #notion, #org-mode"
        should be turned into
        "#obsidian #markdown #notion #org-mode #data_view #tag_folder #openstreetmap #acl"
        """
        hashtags = re.findall(r'(#[\w -]+)', s)
        sanitized_hashtags = set((str(s).replace('-', '_') for s in hashtags))
        return ' '.join(sanitized_hashtags)

    msg = "Your response should only include hashtags, and try to generate as many hashtags as you can! Tokenize the hashtags of this transcript: " + msg

    model = TextGenerationModel.from_pretrained("text-bison@001")
    parameters = {
        "temperature": 0.95,
        "max_output_tokens": 1024,
        "top_p": 0.99,
        "top_k": 40,
    }

    response = model.predict(msg, **parameters)
    
    return sanitize_hashtags(response.text)


random_emojis = 'â“ğŸ¹ğŸš¨â†©ï¸âºğŸ„ğŸ“ ğŸˆ´ğŸŒ‹ğŸ‘½ğŸ’³ğŸ”°ğŸ“ğŸ“ºğŸ´â¬œï¸ğŸ••ğŸ³ğŸ”¼ğŸ˜»ğŸ‹ğŸŒ–ğŸ•–ğŸš…ğŸ•¤â±ğŸ”¬â™‰ï¸ğŸ•³ğŸš§ğŸš¿ğŸ¦‚ğŸ—ğŸŒğŸâªâ‰ï¸ğŸ‘°ğŸšœğŸ“¨ğŸ™ğŸ‘…ğŸ’¢ğŸ’¥ğŸ“ŸğŸ‘©ğŸ˜¢ğŸ‰ğŸ“µğŸ¹âœ’ï¸ğŸ’«ğŸ˜Ÿ8ï¸âƒ£â›ğŸ‘±ğŸ’»ğŸ½ğŸ”‡ğŸ—‚ğŸ—³ğŸ½ğŸ˜‰ğŸ‘›ğŸ—ğŸŒ»ğŸˆ¯ï¸ğŸµğŸ¿â›ˆâ²ğŸ’¤ğŸŒºğŸ’ŠğŸˆ¹ğŸğŸ‘¤ğŸ¸ğŸ®ğŸ»ğŸ¾ğŸ©ğŸ–â›¸â™¦ï¸ğŸ­ğŸŸğŸ’¼ğŸ‚ğŸ™ğŸ›¡ğŸ›ğŸšğŸš‹ğŸ«ğŸ˜¨ğŸ’£ğŸ™€ğŸ‰â˜ â›½ï¸ğŸ•¯ğŸˆ‚ï¸ğŸšŸğŸ“‹ğŸ”ƒğŸˆ¸âš«ï¸ğŸ’ˆğŸ—¯â¬…ï¸ğŸ’†ğŸ›ƒğŸ›£ğŸ—¡â–¶ï¸ğŸ‘‡ğŸŒ‡ğŸ‘¬Â©ï¸#ï¸âƒ£â›…ï¸ğŸ«ğŸ•™ğŸ“½ğŸ• ğŸ–ğŸ’˜ğŸ› ğŸ”¤ğŸ“©ğŸ›ğŸˆ³â˜®ğŸ˜ğŸ”ğŸ”ğŸˆğŸ“‘ğŸ‘šğŸğŸ‹ğŸˆ¶ğŸ—¾ğŸšµâ›²ï¸ğŸš¸ğŸ“«ğŸ“ŠğŸµâ˜ºï¸ğŸ ğŸ²ğŸš¢ğŸ‘¯ğŸ¦ğŸš¾ğŸ•¡â„¹ï¸ğŸ´âœ…ğŸ“€ğŸ˜¬ğŸ“ğŸ²ğŸ‘ğŸ¬ğŸˆ·ï¸ğŸ’¬ğŸšğŸŒğŸ¦ğŸ‘â˜ï¸ğŸ“˜ğŸ©ğŸ†—ğŸ«ğŸ›¬ğŸ“·ğŸŒ˜ğŸšğŸ“ğŸ£ğŸ¦ğŸ¨ğŸ”‰ğŸ˜‡ğŸŒ±ğŸ•ğŸ—»ğŸšğŸ’¶ğŸ°ğŸ”ªğŸŒ´â˜¢ã€½ï¸ğŸ”„ğŸ”ğŸš˜ğŸ™„ğŸš®ğŸ“”ğŸ“™ğŸ™ˆğŸ•¦ğŸŒÂ®ï¸ğŸ•ã€°ï¸ğŸš—ğŸ…â™ï¸ğŸ•´ğŸŒŸğŸªğŸ¯ğŸ’ğŸ€ğŸˆğŸ¤ğŸ“›ğŸ•°ğŸ§ğŸ˜©ğŸ’ğŸš„ğŸ”‹ğŸ¾ğŸŒ¤â˜¦ğŸ•ŒğŸ¯ğŸğŸ˜œğŸ“—ğŸğŸ—ğŸ˜£â¡ï¸ğŸš•ğŸ¬ğŸ’ºğŸ‡ğŸƒğŸ‹ğŸ©â˜£ğŸ‘“ğŸ¡ğŸ‘®ğŸ‘²ğŸ’šğŸ˜‘âš±â¤´ï¸ğŸ”ğŸ–ğŸ•‰â”ğŸ­ğŸ“¥ğŸ¼ğŸš‰â†•ï¸ğŸŠâœŒï¸â›“ğŸ‘·ğŸ•¢ğŸ“¢ğŸš“ğŸ‘«ğŸ¨ğŸ³â­ğŸ¡ğŸ‘œğŸ˜–ğŸ’­ğŸ’‚ğŸ“ğŸ”œğŸ˜§ğŸ‘ğŸğŸ“¡ğŸŒ†ğŸŒ—âœ¨â•ğŸ†–ğŸ‘¦ğŸ˜—ğŸ†â™ ï¸ğŸºğŸ˜ºğŸŒ¡ğŸ”•ğŸ”“ğŸ˜„ğŸ˜ƒğŸ®ğŸŒœğŸ¥ğŸ•‹ğŸšŠğŸ’¸ğŸºğŸ¹ğŸ’ğŸ’ªğŸ´ğŸ˜â“‚ï¸ğŸš«â®ğŸ¦ƒğŸ’‰ğŸ‘ğŸ”«ğŸ˜¦6ï¸âƒ£âŒšï¸ğŸŒ²ğŸŒğŸ‘­ğŸ•œğŸ…¾ï¸â˜˜ğŸŒšğŸ—¼ğŸ“‡ğŸ““ğŸ´ğŸŒ·ğŸ“‰ğŸ†â°1ï¸âƒ£ğŸ”€3ï¸âƒ£ğŸ‡ğŸºğŸ‘¼ğŸ”´ğŸ‘ğŸ›ğŸš€ğŸ“¿ğŸ“ƒğŸ–ğŸ˜·âœğŸ˜•ğŸ•ğŸˆğŸ˜¸ğŸ”›ğŸ›…ğŸŒŠğŸ˜â›¹ğŸŒ ğŸ·ğŸ’¿ğŸŠğŸ“ğŸ¤â›„ï¸ğŸ¾â–ªï¸ğŸ˜’ğŸ”–ğŸŒğŸ§€ğŸŒğŸƒğŸ˜¹â‡ï¸ğŸ’°ğŸ›9ï¸âƒ£ğŸŒğŸ–±ğŸ‘†ğŸ•˜ğŸ†”ğŸ‘¨ğŸš›ğŸš£ğŸ“2ï¸âƒ£ğŸ‡ğŸ’¡ğŸ™ğŸ˜¯ğŸ†*âƒ£â–ğŸ†•â„ï¸ğŸ”¹ğŸˆšï¸âœğŸ…ğŸ›‹ğŸ˜³â—¼ï¸ğŸ“…ğŸš¹ğŸ˜¥ğŸ£ğŸ–²â™‹ï¸ğŸ•—ğŸšˆğŸ’½ğŸğŸ‡ğŸŒˆâ›µï¸â«ğŸ˜›â™ï¸ğŸ”ğŸ†“ğŸ‰ğŸ¤ğŸš½ğŸğŸ™ŠğŸ“ğŸğŸ˜ŠğŸ‘ŠğŸ˜­ğŸ›‚ğŸ“ğŸˆ²ğŸ‘‘ğŸ“–ãŠ—ï¸ğŸ”¨ğŸ¢ğŸ½â–«ï¸ğŸŠâ™ˆï¸âœ´ï¸ğŸš­ğŸ˜˜ğŸ”‚ğŸ˜ ğŸ¦€ğŸğŸ˜“â¹ğŸ“°ğŸ„ğŸ˜¼ğŸš±ğŸ°ğŸŒ®ğŸ•¸â­•ï¸ğŸ’”ğŸ‘€ğŸ¸ğŸ˜ğŸ“»ğŸ‘£â†”ï¸ğŸš¡ğŸâ£ğŸ†™ğŸ•›ğŸ•·ğŸ›«ğŸ”¡ğŸ®ğŸ§ğŸ”ŠğŸ”ŸğŸŒâ˜‘ï¸ğŸ­ğŸ¤‘ğŸšğŸŒªğŸ’€ğŸ˜±ğŸğŸ”½ğŸš5ï¸âƒ£ğŸŒ‘ğŸ‘”ğŸ‘¢ğŸŒµâ¬†ï¸ğŸŒ€ğŸˆğŸğŸ•ğŸ›Œ7ï¸âƒ£ğŸ¯â—½ï¸ğŸšğŸ›ğŸŒ¼ğŸ¨ğŸ€ğŸ˜ŒğŸ˜‹â¬ğŸ“œğŸ“²âœ³ï¸ğŸ˜¾ğŸ‘âš”ğŸ¹ğŸ“’ğŸš â›ºï¸ğŸ•šğŸš»â™¿ï¸ğŸ“¤ğŸ‘ğŸ¤ğŸš¥â™ï¸ğŸ”¶ğŸŒ’âš™ğŸšğŸ™†âš¾ï¸ğŸ˜¤â›”ï¸ğŸ—¨ğŸ“ğŸ‰â™¥ï¸ğŸš†ğŸ¿ğŸªğŸ‘ğŸ’ğŸ’ğŸ¼â†–ï¸ğŸ¡ğŸ…±ï¸â°âŒğŸŒ§ğŸ”»ğŸ•“ğŸ•ğŸ˜µğŸ‘—ğŸ¢ğŸ˜ğŸ›ğŸ™ğŸ•ğŸğŸŒ¾âğŸ’‘ğŸš·ğŸ—½ğŸ”³ğŸŒ„ğŸŒğŸ‘ğŸ¶ğŸ“®ğŸš´ğŸŒ“â›ªï¸â—€ï¸ğŸ®ğŸŒ¹ğŸ—¿ğŸŒƒğŸ–Œâ—ï¸ğŸ¤“ğŸ—œğŸŒ¯ğŸ€ğŸŒ­ğŸ˜™ğŸ’“ğŸ¤’ğŸ‚â—¾ï¸ğŸ”ğŸ…¿ï¸ğŸ¤ğŸ”¥ğŸ“§ğŸ©ğŸ ğŸƒğŸ›¤ğŸŒ«ğŸ•‘ğŸ™‹ğŸŒğŸ™ƒğŸ³ğŸ–¨âšœğŸ”²ğŸœğŸ”â¬‡ï¸ğŸ—ƒğŸ‘‰âœ‚ï¸ğŸš™ğŸğŸŠğŸ‘ğŸ»ğŸ’¨â˜‚ğŸ›³ğŸ‘³ğŸ’„âš¡ï¸ğŸŒ•ğŸŒ¥âš°â¸â˜ªğŸ“¸ğŸ…ğŸ“„ğŸ­ğŸ“³ğŸŒ½ğŸ–‡ğŸ˜ğŸ˜…ğŸ¿âš ï¸âœ”ï¸ğŸ†‘â˜”ï¸ğŸš’ğŸ“´ğŸ“¶ğŸŒğŸ”šâ—ğŸˆâ›±ğŸƒğŸ’ŒğŸ‘»ğŸŒ¿ğŸ˜”â—»ï¸ğŸŒ‰ğŸ––â˜„ğŸ‘™ğŸ’âŒ¨â›·ğŸ’—ğŸ•¹0ï¸âƒ£ğŸ†šâ›°ğŸ”…âğŸ“¹ğŸŸğŸ»ğŸ’œğŸ™ğŸ˜ğŸ¦ğŸ”±âš“ï¸ğŸ—’ğŸ„ğŸ¤˜ğŸ”™ğŸ˜¶ğŸ•ğŸ”¸ğŸš°ğŸ”’ğŸ£ğŸš¤ğŸ±ğŸªâ›‘ğŸ°ğŸ‘¥ğŸ›ğŸ’®ğŸ–•ğŸ—ºğŸ’ğŸ¤—ğŸ”¯â™¨ï¸ğŸ€ğŸ¤”ğŸ’´ğŸ”§ğŸ‘ŒğŸ…°ï¸â•â­ï¸ğŸğŸ”ŒğŸšğŸ›ğŸ˜®â™ï¸ğŸœğŸ”ğŸğŸ’ƒğŸ‘ƒğŸ“¦ğŸ”—âœ–ï¸ğŸ—ğŸ”µğŸŒ‚ğŸ¨ğŸ’·âš½ï¸ğŸ˜ªğŸšŒğŸ”†ğŸŒ…ğŸ·â˜¯ğŸ–ŠğŸ”ˆğŸğŸˆºâ†—ï¸ğŸ¬ğŸ‘’ğŸ“ªğŸ›€ğŸ™‚âš—ğŸ™‡ğŸ˜¡ğŸğŸ¶ğŸğŸŒ¦ğŸ’¹ğŸ¥ğŸ‘ºâ™’ï¸ğŸ’²ğŸ”®â˜ï¸ğŸ‘ªğŸ“­ğŸš©ğŸ””ğŸğŸ•¶âšªï¸ğŸ’âœ‰ï¸ğŸ¡ğŸµğŸ˜†ğŸ‘‹âŒ›ï¸ğŸŒ¨ğŸ’±ğŸ—ğŸ’–âš–ğŸ˜°ğŸºğŸ™ğŸšğŸ™ŒğŸ—„ğŸ”£ğŸšğŸ â¬›ï¸ğŸ†â©ğŸ¸ğŸ•¥ğŸ˜ğŸ ğŸš‚ğŸ’©ğŸŒ›ãŠ™ï¸â˜¹â˜¸âœŠğŸ‘µğŸ”¢âš’ğŸƒâ™Œï¸ğŸ‚ğŸ“šğŸ—£ğŸ˜¿â™»ï¸ğŸ“ˆğŸ›„ğŸš³â™“ï¸ğŸ’ŸğŸ”ğŸ—ğŸ” ğŸ±â™£ï¸ğŸ‹ğŸ•ŸğŸ‘ˆğŸŒ™ğŸ“•ğŸ–¥ğŸ›¥ğŸˆµğŸ¥â™‘ï¸ğŸ±ğŸŒ¸â†™ï¸ğŸ›©ğŸ”©ğŸ˜´ğŸ˜ğŸ¥ğŸ‘„ğŸ˜²ğŸ‘§ğŸ‘´ğŸ’µğŸŒ”ğŸ•’ğŸ”­ğŸµğŸ“†ğŸ˜ˆğŸ‰ğŸ³ğŸ¦ğŸ’›ğŸ›°ğŸš¦ğŸ…ğŸ‘‚âœï¸4ï¸âƒ£ğŸ™ğŸ˜«ğŸ’ ğŸš”ğŸ™…ğŸ–‹ğŸ–¼ğŸ“‚ğŸªâ›©ğŸ“¬ğŸ€„ï¸ğŸ”ğŸšƒğŸ‘¿ğŸ–ğŸğŸ“¼ğŸ«ğŸ‚ğŸ’•ğŸ’ğŸ‘–ğŸ˜šğŸ·ğŸ‘¶ğŸ¦„ğŸ”·ğŸ’…â˜ï¸ğŸğŸ˜‚ğŸ§ğŸ˜½ğŸ¬ğŸŸâ›´ğŸ™‰ğŸŒ³ğŸ•ŠğŸŸğŸš¯â¿ğŸ¼ğŸ“Œâ˜ƒğŸ’‹ğŸâ˜•ï¸ğŸ„ğŸŒ°ğŸ¤–ğŸ¢ğŸšºğŸšªâ„¢ï¸ğŸ”˜ğŸ”¦ğŸ’§ğŸ¸âœ‹ğŸ’ğŸ‘Ÿâ€¼ï¸â¯âœ¡ğŸ¶ğŸ²ğŸ“£ğŸ”ºğŸ‘¹ğŸš¼ğŸ£ğŸğŸ—“ğŸ’™ğŸ›ğŸŒ¬ğŸ‘˜ğŸœğŸ—‘ğŸ”‘ğŸ¯ğŸ’¦ğŸš²ğŸŒ©ğŸ‘¡ğŸ–â†˜ï¸ğŸ†ğŸ“¯âœˆï¸ğŸŒŒğŸ˜€ğŸ‘•â™Šï¸â¤ï¸ğŸ“±â˜€ï¸ğŸ“ğŸ•µâ³ğŸ‘ğŸ’’ğŸ•”ğŸ†˜ğŸ‘¾â›³ï¸ğŸŒ¶ğŸ†’â¤µï¸ğŸğŸ•£ğŸ›¢ğŸ¢ğŸ‘ ğŸ¤•ğŸ°ğŸ’¾ğŸ˜ğŸ“ğŸššğŸš‘â›ğŸ’¯ğŸ‰‘ğŸğŸš‡ğŸ’ğŸš–ğŸš¶ğŸ·ğŸ‘¸ğŸ™ğŸš¬â†ªï¸ğŸ’‡ğŸ•§âš›ğŸ•ğŸ§'

def emojis(msg: str, n: int = 10):
    """ Generate emojis that fit the message. n is the number of emojis that should be generated. """
    def sanitize_emojis(s: str):
        """ Remove anything that is not an emoji, and only return . """
        emojis = re.sub(r'[\w\s\d,\.:ï¿½ğŸ—„]', '', s)
        emojis = emojis if emojis != '' else 'ğŸ™‚'  # use default emoji if it's empty
        return ''.join(take(n, cycle(emojis)))  # reuse emojis until size is n in case we didn't generate enough of them
    
    msg = "Generate fitting emojis for this message, but return only the emojis without any text or punctuation: " + msg

    model = TextGenerationModel.from_pretrained("text-bison@001")
    parameters = {
        "temperature": 0.95,
        "max_output_tokens": n * 4,  # a token is about 4 characters, so we multiply by 4
        "top_p": 0.90,
        "top_k": 40,
    }

    response = model.predict(msg, **parameters)

    return sanitize_emojis(response.text)


def unique_emojis(msg: str, n: int = 10):
    unique_emojis = set(emojis(msg, n))

    # add random emojis until we have enough unique emojis, in case we didn't have enough before
    i = 0
    while len(unique_emojis) < n + 1:
        unique_emojis.add(random_emojis[randint(0, len(random_emojis) + 1)])
        i += 1
        if i > 10000:
            break  # avoid infinite loops
    
    return ''.join(take(n, cycle(unique_emojis)))


def add_emojis(msg: str):
    msg = "Add fitting emojis to this message, but don't change the message itself: " + msg

    model = TextGenerationModel.from_pretrained("text-bison@001")
    parameters = {
        "temperature": 0.95,
        "max_output_tokens": 1024,
        "top_p": 0.90,
        "top_k": 40,
    }

    response = model.predict(msg, **parameters)

    return response.text

